---
title: "creative_chapter"
output: html_document
---
# Analysis for Translating science fiction in a CAT tool: post-editing effort and text segmentation 

## Loading Packages
```{r message=FALSE, warning=FALSE}
library(reshape2)
library(irr)
library(lme4)
library(lmerTest)
library(generics)
library(doBy)
library(pracma)
library(ggplot2)
library(gridExtra)
library(car)
library(MuMIn)
library(testit)
library(tidyverse)
library(glue)
library(ggeffects)
```

## Study 1
Comparing cognitive effort (number of pauses - Green et al. 2013; Toral et al. 2018) between T (translation) and P (post-editing) coditions

### Load data 
Reads in and cleans data from the concatenated CRITT sg tables.
```{r}
Cdata <- read.csv("../data/CREATIVE.csv") #Concatenated CRITT sg tables

# Excluding errors (e.g. participants who forgot to use Pinyin) + cases where there's evidence of MT use in translation condition
Cdata <- subset(Cdata, Part != "P01" & Part != "P04" & Part != "P09" & Part != "P10" & Part != "P12" & Part != "P14" & Part != "P11") 

used_columns<-c("Part","SegId","Text","Task","TB300","LenS")
Cdata<-Cdata[used_columns]

#Fix data type for categorical columns:
Cdata$Part <- as.factor(Cdata$Part)
Cdata$SegId <- as.factor(Cdata$SegId)
Cdata$Text <- as.factor(Cdata$Text)
Cdata$Task <- as.factor(Cdata$Task)

summary(Cdata)

Cdata$OLRE <- c(1:nrow(Cdata)) #adding observation-level random effect that may be used to absorb overdispersion 
```

### Data Structure
This is a unit digram of the structure of the data (not the structure of the model).

```{r, echo=FALSE}
DiagrammeR::grViz("digraph {
  
graph[layout = dot]

node[shape=rectangle]

task1 [label='Post-editing']
task2 [label='Machine Translated']

text1 [label='Text 1']
text2 [label='Text 2']

segment1 [label='Segment 1']
segment2 [label='Segment 2']
segment3 [label='Segment 3']
segment4 [label='Segment 4']
segment5 [label='Segment 5']
segment6 [label='Segment 6']
segment7 [label='Segment 7']
segment8 [label='Segment 8']

participant1 [label = 'Participant 1']
participant2 [label = 'Participant 2']
participant3 [label = 'Participant 3']

task1->segment1
task1->segment2
task1->segment3
task1->segment4
task1->segment5
task1->segment6
task1->segment7
task1->segment8

task2->segment1
task2->segment2
task2->segment3
task2->segment4
task2->segment5
task2->segment6
task2->segment7
task2->segment8

text1->segment1
text1->segment2
text1->segment3
text1->segment4

text2->segment5
text2->segment6
text2->segment7
text2->segment8

segment1 -> participant1
segment2 -> participant1
segment3 -> participant1
segment4 -> participant1
segment5 -> participant1
segment6 -> participant1
segment7 -> participant1
segment8 -> participant1

segment1 -> participant2
segment2 -> participant2
segment3 -> participant2
segment4 -> participant2
segment5 -> participant2
segment6 -> participant2
segment7 -> participant2
segment8 -> participant2

segment1 -> participant3
segment2 -> participant3
segment3 -> participant3
segment4 -> participant3
segment5 -> participant3
segment6 -> participant3
segment7 -> participant3
segment8 -> participant3

}")
```

### Renaming and scaling variables
#### Mean pauses per character between the P and T conditions
The `TB300` variable represents the number of typing bursts interspersed by 300-millisecond intervals. The number of typing bursts is largely equivalent to the number of pauses except for a probable initial and final pause. We therefore calculate the total number of pauses by adding 2 to the `TB300` variable.
```{r}
Cdata$Pauses <- Cdata$TB300 + 2
```

We scale the sentence length `LenS`, to get it on a similar scale to the other variables (this aids computation).
```{r}
Cdata$scaledLen <- as.vector(scale(Cdata$LenS))
```

### Exploratory Data Analysis
```{r}
obs_1 <-nrow(Cdata) #156
print(glue("Study 1 data has {obs_1} observations."))
```

#### Pauses
```{r}
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7") #colour-blind friendly from http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette 
ggplot(Cdata, aes(x=Task,y=Pauses,color=Task))+geom_boxplot()+geom_jitter()+scale_colour_manual(values=cbPalette)
```

```{r}
mean_pauses_per_char_P <- mean((Cdata[ which(Cdata$Task == "P"),]$Pauses)/Cdata[ which(Cdata$Task == "P"),]$LenS) #P: 0.4394113 pauses/character

mean_pauses_per_char_T <- mean((Cdata[ which(Cdata$Task == "T"),]$Pauses)/Cdata[ which(Cdata$Task == "T"),]$LenS) #T: 0.5794642 pauses/character

reduced_pc <- 100*(1-round(mean_pauses_per_char_P/mean_pauses_per_char_T, digits=3))
print(glue("There are more pauses per character in translation on average - {reduced_pc}% reduction for the `P` condition")) #24.2%
```

```{r}
ggplot(Cdata, aes(x=LenS, y=Pauses,color=Task,shape=Part)) + geom_point() +geom_smooth(aes(group=Task),formula='y~x',method='lm',size=0.5, alpha=0.2)+scale_colour_manual(values=cbPalette)
```

```{r}
ggplot(Cdata, aes(x=Part,y=Pauses,fill=Task)) + geom_boxplot() + geom_jitter(alpha=0.25) + scale_fill_manual(values=cbPalette)
```
The average number of pauses is lower for 4 out of 6 participants in the post-editing (`P`) task.

#### Average pause length per segment
The `TG300` variable is the total pause time at the 300-millisecond pause threshold. This is divided by Pauses (`TB300+2`) to get the average pause length per segment. <!--TODO: It's currently not, so ask Lucas about that and amend accordingly.-->
```{r}
mean_pause_len_per_seg_P <- mean(Cdata[ which(Cdata$Task == "P" & Cdata$TG300 >0),]$TG300/(Cdata[ which(Cdata$Task == "P" & Cdata$TG300 >0),]$TB300+1))

mean_pause_len_per_seg_T<-mean(Cdata[ which(Cdata$Task == "T" & Cdata$TG300 >0),]$TG300/(Cdata[ which(Cdata$Task == "T" & Cdata$TG300 >0),]$TB300+1))

# TODO: tidy/check results
mean_pause_len_per_seg_T
mean_pause_len_per_seg_P
```

### Generalized Linear Mixed-Effects model

#### Fixed and Random effects
##### Fixed effects
The task `Task` (which can be either Post-editing `P` or Translation `T`) must be a fixed variable, since:
1. As the predictive variable that we're interested in, these levels have special meaning, and we expect different results for these different variables.
1. these categories are not sampled from a larger pool of possible categories.   

Sentence Length `scaledLen` must be a fixed variable, since it is continuous. 

##### Random effects
Segment `SegId` and participant `Part` are both treated as random effects, since both have a number of interchangeable levels, which are sampled from a large pool of possible levels. These effects are crossed rather than nested.

#### Independence of `SegId`/exlusion of `Text`
<!--
NOTE: I originally thought that Text and Task were equivalent, but n

Since all of the segments for one task are from the same text, the segments are not strictly independent. However, the texts are are similar (according to the Coh-Metrix text analysis tool) and by the same author, meaning that we do not expect sentences from the two texts to be noticeably different. 

It is not possible to include `Text` in the model, since each `Text` only occurs in one `Task`.`
-->

#### Model selection pipeline
##### Maximal design allowed by the experiment
The maximal model is the one that includes random effects (slopes, intercepts, and correlations between them) for all random effects that could possibly be estimated from the structure of the data.

For our data, this means not including a random effect for `Text`, but including random effects for participants (`Part`) and segment (`SegId`), with respect to the `Task` and the sentence length (`scaledLen`).

### Overdispersion
```{r}
overdisp_fun <- function(model, model_name, alpha=0.05){
    rdf <- df.residual(model)
    rp <- residuals(model,type="pearson")
    Pearson.chisq <- sum(rp^2)
    prat <- Pearson.chisq/rdf
    pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
    if (pval<alpha){
    print(glue('The model `{model_name}` is overdispersed, p-value: {pval}'))
    }
    else {
      print(glue('The model `{model_name}` is not overdispersed, p-value:{pval}'))
    }
    c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}

overdispersion <- overdisp_fun(maximal_model_a, 'maximal_model_a') 
```

### Model selection
```{r}
maximal_model <- glmer(Pauses ~ Task + scaledLen + (1+Task|Part) + (1+Task|Text/SegId)+ (1+scaledLen|Part) + (1+scaledLen|Text/SegId), data=Cdata, family="poisson") 
isSingular(maximal_model)
```

This model is singular, so it's necessary to try a simpler model structure.

We first remove the correlation parameter between the random intercept for each segment (`SegId`) and the random slopes of each segment within scaledLen.

```{r}
maximal_model_a <- glmer(Pauses ~ Task + scaledLen + (Task|Part) + (Task|Text/SegId)+ (scaledLen|Part) + (0+scaledLen|Text/SegId), data=Cdata, family="poisson") 
isSingular(maximal_model_a)
```
This fit is also is singular.

We then remove the correlation parameter between the random intercept for each participant (`Part`) and the random slopes of each participant within scaledLen.

```{r}
maximal_model_b <- glmer(Pauses ~ Task + scaledLen + (Task|Part) + (Task|Text/SegId)+ (0+scaledLen|Part) + (0+scaledLen|Text/SegId), data=Cdata, family="poisson") 

maximal_model_b <- glmer(Pauses ~ Task + scaledLen + (Task|Part) + (Task|Text/SegId)+ (0+scaledLen|Part) + (0+scaledLen|Text/SegId), data=Cdata, family="poisson", glmerControl(optimizer = 'bobyqa'))

isSingular(maximal_model_b)
```
This fit does not converge with the default optimiser. When using the `bobyqa` optimiser, we see that the model converges, but again is singular.

We then remove the correlation parameter between segment and task, then the correlation between participant and task, both of which result in singular fits. 

```{r}
maximal_model_c <- glmer(Pauses ~ Task + scaledLen + (Task|Part) + (1|Text/SegId) + (0+Task|Text/SegId)+ (0+scaledLen|Part) + (0+scaledLen|Text/SegId), data=Cdata, family="poisson") 
isSingular(maximal_model_c)

maximal_model_d <- glmer(Pauses ~ Task + scaledLen + (1|Part)+(0+Task|Part) + (1|Text/SegId) + (0+Task|Text/SegId)+ (0+scaledLen|Part) + (0+scaledLen|Text/SegId), data=Cdata, family="poisson") 
isSingular(maximal_model_d)
```

At this point it is then necessary to remove random slopes or intercepts.

```{r}
maximal_model_e <- glmer(Pauses ~ Task + scaledLen + (1|Part)+(0+Task|Part) + (1|Text/SegId) + (0+Task|Text/SegId) + (0+scaledLen|Part), data=Cdata, family="poisson") # remove  (0+scaledLen|Text/SegId) 
isSingular(maximal_model_e) 
overdisp_fun(maximal_model_e,"maximal_model_e")

maximal_model_e.OLRE <- glmer(Pauses ~ Task + scaledLen + (1|Part)+(0+Task|Part) + (1|Text/SegId) + (0+Task|Text/SegId) + (0+scaledLen|Part) + (1|OLRE), data=Cdata, family="poisson",glmerControl(optimizer = 'bobyqa')) # remove  (0+scaledLen|Text/SegId) 
isSingular(maximal_model_e.OLRE) 

maximal_model_f <- glmer(Pauses ~ Task + scaledLen + (1|Part)+(0+Task|Part) + (1|Text/SegId) + (0+scaledLen|Text/SegId)+ (0+scaledLen|Part), data=Cdata, family="poisson",glmerControl(optimizer = 'bobyqa')) # remove (0+Task|Text/SegId), the effect of a given segment on the effectiveness of the treatment
isSingular(maximal_model_f)

maximal_model_g <- glmer(Pauses ~ Task + scaledLen + (1|Part)+(0+Task|Part) + (1|Text/SegId) + (0+scaledLen|Part), data=Cdata, family="poisson",glmerControl(optimizer = 'bobyqa')) # remove (0+scaledLen|Text/SegId), the effect of a given segment on the effectiveness of the treatment
isSingular(maximal_model_g)

maximal_model_h <- glmer(Pauses ~ Task + scaledLen + (1|Part)+(0+Task|Part) + (1|SegId) + (0+scaledLen|Part), data=Cdata, family="poisson",glmerControl(optimizer = 'bobyqa')) # remove (0+scaledLen|Text/SegId), the effect of a given segment on the effectiveness of the treatment
isSingular(maximal_model_h)

maximal_model_i <- glmer(Pauses ~ Task + scaledLen + (1|Part) + (1|SegId) + (0+scaledLen|Part), data=Cdata, family="poisson",glmerControl(optimizer = 'bobyqa')) # remove (0+scaledLen|Text/SegId), the effect of a given segment on the effectiveness of the treatment
isSingular(maximal_model_i)
overdisp_fun(maximal_model_i,"maximal_model_i")

maximal_model_i.OLRE <- glmer(Pauses ~ Task + scaledLen + (1|Part) + (1|SegId) + (0+scaledLen|Part) + (1|OLRE), data=Cdata, family="poisson",glmerControl(optimizer = 'bobyqa'))
isSingular(maximal_model_i.OLRE)
overdisp_fun(maximal_model_i.OLRE,"maximal_model_i.OLRE")
```

```{r}
summary(maximal_model_i.OLRE)
```
```{r}
r.squaredGLMM(maximal_model_i.OLRE)
```

#### Visualising the chosen model
A marginal effects plot using the `ggeffect` package shows how the predicted relationship between `Pauses` and scaled sentence length (`scaledLen`).

```{r}
predict_df1f <- ggpredict(maximal_model_i.OLRE, terms=c("scaledLen","Task"), type='re')
plot(predict_df1f, add.data=TRUE)
```

### Normality Check
However, the residuals are normally distributed according to a Shapiro-Wilk normality test.
```{r}
qqnorm(residuals(maximal_model_i.OLRE))
shapiro <- shapiro.test(residuals(maximal_model_i.OLRE))
alpha <- 0.05
if (shapiro$p.value < alpha){
  print(glue('Residuals are normally distributed according to a Shapiro-Wilk normality test, with p-value {shapiro$p.value}'))
} else {
  print(glue('Residuals are cannot be assumed to be normally distributed according to a Shapiro-Wilk normality test, with p-value: {shapiro$p.value}'))
}
```

## Previous workings

```{r}
Cdata$OLRE <- c(1:nrow(Cdata)) #adding observation-level random effect to absorb overdispersion 

maximal_model_a.OLRE <- glmer(Pauses ~ Task + scaledLen + (1|OLRE)+(Task | Part) + (Task | SegId) + 
    (scaledLen | Part) + (0 + scaledLen | SegId), data=Cdata, family="poisson")
isSingular(maximal_model_a.OLRE)
```

```{r}
model_test.OLRE <- glmer(Pauses ~ Task + scaledLen + (1|Part) + (1|SegId) + (0+Part|scaledLen), data=Cdata, family="poisson") 

model_test.OLRE.overdispersion <- overdisp_fun(model_test.OLRE, 'model_test.OLRE') #overdispersion corrected
```

```{r}
model1f.OLRE <- glmer(Pauses ~ Task + scale(LenS) + (1|Part) + (1|SegId) + (1|OLRE), data=Cdata, family="poisson") #running test on simpler model
model1f.OLRE.overdispersion <- overdisp_fun(model1f.OLRE, 'model1f.OLRE') #overdispersion corrected
summary(model1f.OLRE) #Task effect still significant; model1f retained

#%CHANGE

exp(3.30285) #P 27.2
exp(3.30285+0.35612) #T 38.8

(exp(3.30285+0.35612)-exp(3.30285))/exp(3.30285+0.35612) #30% fewer pauses for P

confint(model1f)

#LOWER BOUND %CHANGE

exp(2.91899650) #P 
exp(2.91899650+0.03133241) #T

(exp(2.91899650+0.03133241)-exp(2.91899650))/exp(2.91899650+0.03133241) #3% fewer pauses for P

#UPPER BOUND %CHANGE

exp(3.6763008) #P 
exp(3.6763008+0.6787899) #T

(exp(3.6763008+0.6787899)-exp(3.6763008))/exp(3.6763008+0.6787899)
#49.3% fewer pauses for P

```


```{r}
model_basic <- glm(Pauses~scaledLen+Task, data=Cdata)
predict_basic <- ggpredict(model_basic, terms=c("scaledLen","Task"))
plot(predict_basic, add.data=TRUE)
```

Comparing keystrokes between translation and post-editing

``` {r}

###Descriptive Stats

mean((Cdata[ which(Cdata$Task == "P"),]$Ins+Cdata[ which(Cdata$Task == "P"),]$Del)/Cdata[ which(Cdata$Task == "P"),]$LenS) #2.473231 keystrokes/character

mean((Cdata[ which(Cdata$Task == "T"),]$Ins+Cdata[ which(Cdata$Task == "T"),]$Del)/Cdata[ which(Cdata$Task == "T"),]$LenS) #4.163049 keystrokes/character

#more keystrokes/word in translation on average - 40% reduction for P condition

###glmer model

model2 <- glmer(Ins+Del ~ Task + scale(LenS) + (1|Part) + (1|SegId), data=Cdata, family="poisson")

model2a <- glmer(Ins+Del ~ Task + scale(LenS) + (0+Task|Part) + (1|Part) + (1|SegId), data=Cdata, family="poisson") #Fails to converge

model2b <- glmer(Ins+Del ~ Task + scale(LenS) + (1+Task|Part) + (1|SegId), data=Cdata, family="poisson")

model2c <- glmer(Ins+Del ~ Task + scale(LenS) + (1|Part) + (1|SegId) + (0+Task|SegId), data=Cdata, family="poisson") #fails to converge

model2d <- glmer(Ins+Del ~ Task + scale(LenS) + (1|Part) + (1|SegId) + (0+Task|SegId), data=Cdata, family="poisson") #fails to converge

model2e <- glmer(Ins+Del ~ Task + scale(LenS) + (1|Part) + (1|SegId) + (0+Task|SegId) + (0+Task|Part), data=Cdata, family="poisson") #fails to converge

model2f <- glmer(Ins+Del ~ Task + scale(LenS) + (1+Task|Part) + (1+Task|SegId), data=Cdata, family="poisson")

model2g <- glmer(Ins+Del ~ Task + scale(LenS) + (1|Part) + (0+Task|Part) + (1+Task|SegId), data=Cdata, family="poisson") #faisl to converge

model2h <- glmer(Ins+Del ~ Task + scale(LenS) + (1|SegId) + (0+Task|SegId) + (1+Task|Part), data=Cdata, family="poisson") #fails to converge

anova(model2, model2b)
anova(model2b, model2f) #2f superior

summary(model2f) #chosen model  - more keystrokes in translation

r.squaredGLMM(model2f) #R2

#Overdispersion
overdisp_fun(model2f) #model is overdispersed

model2f.OLRE <- glmer(Ins+Del ~ Task + scale(LenS) + (1+Task|Part) + (1+Task|SegId) + (1|OLRE), data=Cdata, family="poisson")
isSingular(model2f.OLRE) #model is singular

model2f.OLRE <- glmer(Ins+Del ~ Task + scale(LenS) + (1|Part) + (1|SegId) + (1|OLRE), data=Cdata, family="poisson") #running test on simpler model
overdisp_fun(model2f.OLRE) #overdispersion corrected 
summary(model2f.OLRE) #Task effect still significant; model2f retained

#%CHANGE

exp(4.98902) #P 
exp(4.98902+0.66531) #T 

(exp(4.98902+0.66531)-exp(4.98902))/exp(4.98902+0.66531) #48.5% fewer keystrokes for T

confint(model2f)

#LOWER BOUND %CHANGE

exp(4.5219869) #P 
exp(4.5219869+0.2917585) #T

(exp(4.5219869+0.2917585)-exp(4.5219869))/exp(4.5219869+0.2917585) #25.3% fewer keystrokes for P

#UPPER BOUND %CHANGE

exp(5.4458643) #P
exp(5.4458643+1.0501244) #T

(exp(5.4458643+1.0501244)-exp(5.4458643))/exp(5.4458643+1.0501244)
#65% fewer keystrokes for P

```
Comparing temporal effort between translation and post-editing
```{r}
###Descriptive stats

mean(Cdata[ which(Cdata$FDur >0 & Cdata$Task == "P"),]$FDur/Cdata[ which(Cdata$FDur >0 & Cdata$Task == "P"),]$LenS) #2.7s/character

mean(Cdata[ which(Cdata$FDur >0 & Cdata$Task == "T"),]$FDur/Cdata[ which(Cdata$FDur >0 & Cdata$Task == "T"),]$LenS) #3.7s/character

#Time per word longer in Translation

### lmer model

model3 <- lmer(log(FDur) ~ Task + scale(LenS) + (1|Part) + (1|SegId), data=Cdata[ which(Cdata$FDur >0),])

model3a <- lmer(log(FDur) ~ Task + scale(LenS) + (0+Task|Part) + (1|Part) + (1|SegId), data=Cdata[ which(Cdata$FDur >0),]) #fails to converge

model3b <- lmer(log(FDur) ~ Task + scale(LenS) + (1+Task|Part) + (1|SegId), data=Cdata[ which(Cdata$FDur >0),])

model3c <- lmer(log(FDur) ~ Task + scale(LenS) + (1|Part) + (1|SegId) + (0+Task|SegId), data=Cdata[ which(Cdata$FDur >0),]) #fails to converge

model3d <- lmer(log(FDur) ~ Task + scale(LenS) + (1|Part) + (1|SegId) + (0+Task|SegId), data=Cdata[ which(Cdata$FDur >0),]) #fails to converge

model3e <- lmer(log(FDur) ~ Task + scale(LenS) + (1|Part) + (1|SegId) + (0+Task|SegId) + (0+Task|Part), data=Cdata[ which(Cdata$FDur >0),]) #fails to converge

model3f <- lmer(log(FDur) ~ Task + scale(LenS) + (1+Task|Part) + (1+Task|SegId), data=Cdata[ which(Cdata$FDur >0),])

model3g <- lmer(log(FDur) ~ Task + scale(LenS) + (1|Part) + (0+Task|Part) + (1+Task|SegId), data=Cdata[ which(Cdata$FDur >0),])

model3h <- lmer(log(FDur) ~ Task + scale(LenS) + (1|SegId) + (0+Task|SegId) + (1+Task|Part), data=Cdata[ which(Cdata$FDur >0),]) #fails to converge

anova(model3, model3b)
anova(model3b, model3f)
anova(model3f, model3g) #model3f superior

summary(model3f) #chosen model - no difference between translation and post-editing

###model criticism

# heterodasticity
plot(fitted(model3), resid(model3)) #looks fine

# normality
qqp(resid(model3)) #looks fine

r.squaredGLMM(model3)

```
## Study 2
Comparing different ways of presenting the texts on screen (sentence- and paragraph-level segmentation).

### Loading Data
```{r}
Cdata2 <- read.csv("../data/CREATIVE2.csv") #Concatenated CRITT sg tables
Cdata2 <- subset(Cdata2, Part != "P06") #excluding participant who split paragraphs
```

``` {r}

###Descriptive Stats

mean((Cdata2[ which(Cdata2$Segmentation == "paragraph"),]$Pauses)/Cdata2[ which(Cdata2$Segmentation == "paragraph"),]$LenS) #0.3480152 pauses/character

mean((Cdata2[ which(Cdata2$Segmentation == "sentence"),]$Pauses)/Cdata2[ which(Cdata2$Segmentation == "sentence"),]$LenS) #0.4222854 pauses/character

mean(Cdata2[ which(Cdata2$Segmentation == "paragraph" & Cdata2$TG300 > 0),]$TG300/(Cdata2[ which(Cdata2$Segmentation == "paragraph" & Cdata2$TG300 > 0),]$TB300+1)) #5.5s per pause 

mean(Cdata2[ which(Cdata2$Segmentation == "sentence" & Cdata2$TG300 > 0),]$TG300/(Cdata2[ which(Cdata2$Segmentation == "sentence" & Cdata2$TG300 > 0),]$TB300+1)) # 4.2s per pause

#more pauses per source character in sentence condition on average - 18% reduction in number of pauses for paragraoh condition compared to sentence condition


###glmer model

model4 <- glmer(Pauses ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg), data=Cdata2, family="poisson")

model4a <- glmer(Pauses ~ Segmentation + scale(LenS) + (0+Segmentation|Part) + (1|Part) + (1|TTseg), data=Cdata2, family="poisson") 

model4b <- glmer(Pauses ~ Segmentation + scale(LenS) + (1+Segmentation|Part) + (1|TTseg), data=Cdata2, family="poisson")

model4c <- glmer(Pauses ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg), data=Cdata2, family="poisson") #fails to converge

model4d <- glmer(Pauses ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg), data=Cdata2, family="poisson") #fails to converge

model4e <- glmer(Pauses ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg) + (0+Segmentation|Part), data=Cdata2, family="poisson") #fails to converge

model4f <- glmer(Pauses ~ Segmentation + scale(LenS) + (1+Segmentation|Part) + (1+Segmentation|TTseg), data=Cdata2, family="poisson") #fails to converge

model4g <- glmer(Pauses ~ Segmentation + scale(LenS) + (1|Part) + (0+Segmentation|Part) + (1+Segmentation|TTseg), data=Cdata2, family="poisson") 

model4h <- glmer(Pauses ~ Segmentation + scale(LenS) + (1|TTseg) + (0+Segmentation|TTseg) + (1+Segmentation|Part), data=Cdata2, family="poisson") #fails to converge


anova(model4, model4a)
anova(model4a, model4b)
anova(model4a, model4g) #a superior

summary(model4a) #more pauses in sentence condition 

### glmer model without random effect for items

Cdata2$Text = as.factor(Cdata2$Text)
contrasts(Cdata2$Text) = contr.sum(2)

model9 <- glmer(Pauses ~ Segmentation + scale(LenS) + Text + (1|Part), data=Cdata2, family="poisson")

model9a <- glmer(Pauses ~ Segmentation + scale(LenS)  + Text + (0+Segmentation|Part) + (1|Part), data=Cdata2, family="poisson") #fails to converge

model9b <- glmer(Pauses ~ Segmentation + scale(LenS) + Text + (1+Segmentation|Part), data=Cdata2, family="poisson")

anova(model9, model9b) #model 9b superior

summary(model9b) #more pauses in sentence condition 

r.squaredGLMM(model9b) #R2

#Overdispersion

overdisp_fun(model9b) #model overdispersed
Cdata2$OLRE <- c(1:nrow(Cdata2)) #adding observation-level random effect to absord overdispersion 

model9b.OLRE <- glmer(Pauses ~ Segmentation + scale(LenS) + Text + (1+Segmentation|Part) + (1|OLRE), data=Cdata2, family="poisson")
isSingular(model9b.OLRE) #FALSE - not singular

summary(model9b.OLRE) #Segmentation still significant 
overdisp_fun(model9b.OLRE) #overdispersion corrected

#%CHANGE

exp(2.97011) #para 
exp(2.97011+0.51973) #sent

(exp(2.97011+0.51973)-exp(2.97011))/exp(2.97011+0.51973) #40% fewer pauses for paragraph segmentation

confint(model9b)

#LOWER BOUND %CHANGE

exp(2.6461603) #para 
exp(2.6461603+0.2000460) #sent

(exp(2.6461603+0.2000460)-exp(2.6461603))/exp(2.6461603+0.2000460) #18% fewer pauses for paragraph segmentation

#UPPER BOUND %CHANGE

exp(3.2921073) #para 
exp(3.2921073+0.8411030) #sent

(exp(3.2921073+0.8411030)-exp(3.2921073))/exp(3.2921073+0.8411030)
#56.9% fewer pauses for paragraph segmentation

```

Comparing keystrokes between translation and post-editing
```{r}
###Descriptive Stats

mean((Cdata2[ which(Cdata2$Segmentation == "paragraph"),]$Ins+Cdata2[ which(Cdata2$Segmentation == "paragraph"),]$Del)/Cdata2[ which(Cdata2$Segmentation == "paragraph"),]$LenS) #1.758849 keystrokes/character

mean((Cdata2[ which(Cdata2$Segmentation == "sentence"),]$Ins+Cdata2[ which(Cdata2$Segmentation == "sentence"),]$Del)/Cdata2[ which(Cdata2$Segmentation == "sentence"),]$LenS) #2.401009 keystrokes/character

#more keystrokes per source word on average in sentence condition - 26.7% reduction in the number of keystrokes for paragraph condition

###glmer model

model5 <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg), data=Cdata2, family="poisson")

model5a <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (0+Segmentation|Part) + (1|Part) + (1|TTseg), data=Cdata2, family="poisson") #fails to converge

model5b <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (1+Segmentation|Part) + (1|TTseg), data=Cdata2, family="poisson")

model5c <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg), data=Cdata2, family="poisson") #fails to converge

model5d <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg), data=Cdata2, family="poisson") #fails to converge

model5e <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg) + (0+Segmentation|Part), data=Cdata2, family="poisson") #fails to converge

model5f <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (1+Segmentation|Part) + (1+Segmentation|TTseg), data=Cdata2, family="poisson") 

model5g <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (1|Part) + (0+Segmentation|Part) + (1+Segmentation|TTseg), data=Cdata2, family="poisson") #fails to converge

model5h <- glmer(Ins+Del ~ Segmentation + scale(LenS) + (1|TTseg) + (0+Segmentation|TTseg) + (1+Segmentation|Part), data=Cdata2, family="poisson") 

anova(model5, model5b)
anova(model5b, model5f)
anova(model5b,model5h) #5b superior

summary(model5b) #more keystrokes in sentence condition

### glmer model without random effect for items

model8 <- glmer(Ins+Del ~ Segmentation + scale(LenS) + Text + (1|Part), data=Cdata2, family="poisson")

model8a <- glmer(Ins+Del ~ Segmentation + scale(LenS)  + Text + (0+Segmentation|Part) + (1|Part), data=Cdata2, family="poisson") #fails to converge

model8b <- glmer(Ins+Del ~ Segmentation + scale(LenS) + Text + (1+Segmentation|Part), data=Cdata2, family="poisson")

anova(model8, model8b) #model 8b superior


summary(model8b) #more keystrokes in sentence condition

r.squaredGLMM(model8b) #R2

#Overdispersion

overdisp_fun(model8b) #model overdispersed

model8b.OLRE <- glmer(Ins+Del ~ Segmentation + scale(LenS) + Text + (1+Segmentation|Part) +(1|OLRE), data=Cdata2, family="poisson")
isSingular(model8b.OLRE) #singular

model8b.OLRE <- glmer(Ins+Del ~ Segmentation + scale(LenS) + Text + (0+Segmentation|Part) + (1|Part) + (1|OLRE), data=Cdata2, family="poisson")

overdisp_fun(model8b.OLRE) #overdispersion corrected

summary(model8b.OLRE) #Segmentation significant

#%CHANGE

exp(4.780328) #para 
exp(4.780328+0.430209) #sent

(exp(4.780328+0.430209)-exp(4.780328))/exp(4.780328+0.430209) #34.9% fewer keystrokes for paragraph segmentation

#####INTERPRETATION####
#Changing from paragraph to sentences multiplies the number of expected keystrokes by exp0.430209), which means that in the sentence condition the number of keystrokes is exp(0.430209)*exp(4.780328) or exp(4.780328+0.430209) [183.1924], while in the paragraph condition, the number is exp(4.780328) [119.1434], a reduction of 34.9% for paragraphs


confint(model8b)

#LOWER BOUND %CHANGE

exp(4.44488946) #para 
exp(4.44488946+0.11706831) #sent

(exp(4.44488946+0.11706831)-exp(4.44488946))/exp(4.44488946+0.11706831) #11% fewer keystrokes for paragraph segmentation

#UPPER BOUND %CHANGE

exp(5.1154987) #para 
exp(5.1154987+0.7435313) #sent

(exp(5.1154987+0.7435313)-exp(5.1154987))/exp(5.1154987+0.7435313)
#52% fewer keystrokes for paragraph segmentation


```
Comparing temporal effort between paragraph and sentence segmentation

```{r}
###Descriptive stats

mean(Cdata2[ which(Cdata2$Segmentation == "sentence" & Cdata2$FDur > 0),]$FDur/Cdata2[ which(Cdata2$Segmentation == "sentence" & Cdata2$FDur > 0),]$LenS) #3s/character

mean(Cdata2[ which(Cdata2$Segmentation == "paragraph"& Cdata2$FDur > 0),]$FDur/Cdata2[ which(Cdata2$Segmentation == "paragraph"& Cdata2$FDur > 0),]$LenS) #2.3s/character

#Time per character longer on average in sentence segmentation - 23.7% reduction for paragraph segmentation

### lmer model 

model6 <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg), data=Cdata2[ which(Cdata2$FDur >0),])

model6a <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (0+Segmentation|Part) + (1|Part) + (1|TTseg), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge

model6b <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1+Segmentation|Part) + (1|TTseg), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge

model6c <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge

model6d <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge

model6e <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg) + (0+Segmentation|TTseg) + (0+Segmentation|Part), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge

model6f <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1+Segmentation|Part) + (1+Segmentation|TTseg), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge

model6g <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1|Part) + (0+Segmentation|Part) + (1+Segmentation|TTseg), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge

model6h <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1|TTseg) + (0+Segmentation|TTseg) + (1+Segmentation|Part), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge 


summary(model6) #Sentence segmentation longer

###model criticism

# heterodasticity
plot(fitted(model6), resid(model6))

# normality
qqp(resid(model6))

Cdata2_sub <- Cdata2[ which(Cdata2$FDur >0),]
Cdata2_no <- Cdata2_sub[abs(scale(resid(model6))) < 2.5,]
(nrow(Cdata2_sub) - nrow(Cdata2_no))/nrow(Cdata2_sub) #2 (approx. 1%) data points removed

model6_no <- lmer(log(FDur) ~ Segmentation + scale(LenS) + (1|Part) + (1|TTseg), data=Cdata2_no)
summary(model6_no) #Segmentation effect still significant

qqp(resid(model6_no))

### lmer model without random effect for items

model7 <- lmer(log(FDur) ~ Segmentation + scale(LenS) + Text + (1|Part), data=Cdata2[ which(Cdata2$FDur >0),])

model7a <- lmer(log(FDur) ~ Segmentation + scale(LenS)  + Text + (0+Segmentation|Part) + (1|Part), data=Cdata2[ which(Cdata2$FDur >0),]) 

model7b <- lmer(log(FDur) ~ Segmentation + scale(LenS) + Text + (1+Segmentation|Part), data=Cdata2[ which(Cdata2$FDur >0),]) #fails to converge

anova(model7, model7a) #7 superior

summary(model7) #Sentence segmentation longer

r.squaredGLMM(model7) #R2
cor(log(Cdata2[ which(Cdata2$FDur >0),]$FDur), fitted(model7))^2 #R2

#%CHANGE

exp(11.17112) #para 
exp(11.17112+0.69744) #sent

(exp(11.17112+0.69744)-exp(11.17112))/exp(11.17112+0.69744)  #50% less time for paragraph segmentation

confint(model7)

#LOWER BOUND %CHANGE

exp(10.7505821) #para 
exp(10.7505821+0.3224180) #sent

(exp(10.7505821+0.3224180)-exp(10.7505821))/exp(10.7505821+0.3224180) #27.5% less time for paragraph segmentation

#UPPER BOUND %CHANGE

exp(11.5922846) #para 
exp(11.5922846+1.0730900) #sent

(exp(11.5922846+1.0730900)-exp(11.5922846))/exp(11.5922846+1.0730900)
#65.8% less time for paragraph segmentation

###model criticism

# heterodasticity
plot(fitted(model7), resid(model7)) #looks fine

# normality
qqp(resid(model7))

Cdata2_sub <- Cdata2[ which(Cdata2$FDur >0),]
Cdata2_no7 <- Cdata2_sub[abs(scale(resid(model7))) < 2.5,]
(nrow(Cdata2_sub) - nrow(Cdata2_no))/nrow(Cdata2_sub) #2 (approx. 1%) data points removed

model7_no <- lmer(log(FDur) ~ Segmentation + scale(LenS) + as.factor(Text)+ (1|Part), data=Cdata2_no7)
summary(model7_no) #Segmentation effect still significant

qqp(resid(model7_no))

confint(model7_no)

#LOWER BOUND %CHANGE

exp(10.9500903) #para 
exp(10.9500903+0.2451603) #sent

(exp(10.9500903+0.2451603)-exp(10.9500903))/exp(10.9500903+0.2451603) #21.7% less time for paragraph segmentation

#UPPER BOUND %CHANGE

exp(11.7011703) #para 
exp(11.7011703+0.9117928) #sent

(exp(11.7011703+0.9117928)-exp(11.7011703))/exp(11.7011703+0.9117928)
#59.8% less time for paragraph segmentation


```

## Reproducibility

### Testing reproducibility
The following code snippets check that the input data, and results are the same as ours to 7 significant figures.

```{r}
sig_fig <- 7

# Check descriptive stats:
m_pc_P <- 0.4394113
testit::assert(glue("Mean pauses/character for post-editing is {m_pc_P}"), round(mean_pause_per_char_P, digits=sig_fig) == m_pc_P)

m_pc_T <- 0.5794642
testit::assert(glue("Mean pauses/character for translation is {m_pc_T}"), round(mean_pause_per_char_T, digits=sig_fig) == m_pc_T)
```

### Snapshot R library environment
```{r}
renv::clean()
renv::snapshot()
```

### Software citations
```{r}
knitr::write_bib(c(.packages(), "bookdown"), "../software-citations.bib")
```



